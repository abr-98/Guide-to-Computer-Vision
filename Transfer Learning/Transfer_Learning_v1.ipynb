{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_Learning_v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6uJ874_zEk7",
        "outputId": "5c3e7be5-e41e-4f53-ac8c-723dbc8ac692"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qxw7PTMzGkL"
      },
      "source": [
        "FLDR='drive/MyDrive/dogs-vs-cats/'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j_FSWqbzgAv"
      },
      "source": [
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u25htS6Kzh8O"
      },
      "source": [
        "files_zip_full=os.listdir(FLDR)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slKIg19WznUN",
        "outputId": "d907ea25-0376-4fb6-aaf3-a9daf7c75143"
      },
      "source": [
        "files_zip_full"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sampleSubmission.csv', 'test1.zip', 'train.zip']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lykxTPLbzoct"
      },
      "source": [
        "train_data=files_zip_full[2]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Un-Wt_UTztKq",
        "outputId": "bd939865-5bbb-4764-9a50-d2f012aeb162"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'train.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvS3Cet7zuFr"
      },
      "source": [
        "import zipfile"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARUI2j1s0Qby"
      },
      "source": [
        "Labels=[]\n",
        "Names=[]\n",
        "\n",
        "archive=zipfile.ZipFile(FLDR+train_data)\n",
        "for f_n in archive.namelist():\n",
        "  print(f_n)\n",
        "  if 'cat' in f_n or 'Cat' in f_n:\n",
        "    Labels.append('cat')\n",
        "    Names.append(f_n.split('/')[1])\n",
        "  if 'dog' in f_n or 'Dog' in f_n:\n",
        "    Labels.append('dog')\n",
        "    Names.append(f_n.split('/')[1])\n",
        "  archive.extract(f_n,FLDR+'extracted')\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNjwJIqC7Ycf"
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQgRWa7z2qsT"
      },
      "source": [
        "df_train=pd.DataFrame(list(zip(Names,Labels)),columns=['Files','Labels'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CcMT5Q96-Pc"
      },
      "source": [
        "df_train=df_train[1:]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9oTybK48CPk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "61044c6c-8043-45b5-a27d-41e84c6f0c07"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Files</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cat.1.jpg</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cat.10.jpg</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cat.100.jpg</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cat.1000.jpg</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>cat.10000.jpg</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Files Labels\n",
              "1      cat.1.jpg    cat\n",
              "2     cat.10.jpg    cat\n",
              "3    cat.100.jpg    cat\n",
              "4   cat.1000.jpg    cat\n",
              "5  cat.10000.jpg    cat"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFSduoiI8PRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b2e978-2789-42f0-cb68-6d6261d3141e"
      },
      "source": [
        "df_train['Labels'].value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dog    12500\n",
              "cat    12499\n",
              "Name: Labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMKtO0ETPXcl"
      },
      "source": [
        "files_zip_full=os.listdir(FLDR)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l83_PqPQ9KLY",
        "outputId": "fa1f49bb-5331-4a0b-a0ed-28ebc71a9be8"
      },
      "source": [
        "files_zip_full"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sampleSubmission.csv', 'test1.zip', 'train.zip', 'extracted']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyGY6geH8wUf"
      },
      "source": [
        "test_Sub=files_zip_full[0]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXpJS52x9SK3"
      },
      "source": [
        "df_sub=pd.read_csv(FLDR+test_Sub)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "lAY_0lK49dBz",
        "outputId": "49cb996e-664f-464b-b02e-9239ac0e655d"
      },
      "source": [
        "df_sub.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label\n",
              "0   1      0\n",
              "1   2      0\n",
              "2   3      0\n",
              "3   4      0\n",
              "4   5      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSUP2o8i9gzp"
      },
      "source": [
        "test_data=files_zip_full[1]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FXFmlCez98YK",
        "outputId": "966de6b1-f0b4-417e-dd49-371a06303d46"
      },
      "source": [
        "test_data"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'test1.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GycAX2c993i"
      },
      "source": [
        "archive=zipfile.ZipFile(FLDR+test_data)\n",
        "for f_n in archive.namelist():\n",
        "  print(f_n)\n",
        "  archive.extract(f_n,FLDR+'extracted_2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xE8_GaP-R2t"
      },
      "source": [
        "def replace_name(name):\n",
        "  name=str(name)+'.jpg'\n",
        "  return name"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmF6PVZr_m4Q"
      },
      "source": [
        "df_sub['id']=df_sub['id'].apply(replace_name)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ZraWJ_C__3P-",
        "outputId": "6f7db01b-f6eb-4f4a-a37f-999c42a9115b"
      },
      "source": [
        "df_sub.tail()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12495</th>\n",
              "      <td>12496.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12496</th>\n",
              "      <td>12497.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12497</th>\n",
              "      <td>12498.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12498</th>\n",
              "      <td>12499.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12499</th>\n",
              "      <td>12500.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              id  label\n",
              "12495  12496.jpg      0\n",
              "12496  12497.jpg      0\n",
              "12497  12498.jpg      0\n",
              "12498  12499.jpg      0\n",
              "12499  12500.jpg      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V6fn4gs_9T-"
      },
      "source": [
        "def replace_labels(name):\n",
        "  return 'cat' if (name==0) else 'dog'"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMxkCY0sAQ-V"
      },
      "source": [
        "df_sub['label']=df_sub['label'].apply(replace_labels)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "gpHLCACnAscr",
        "outputId": "aef4f0a8-de28-4005-d82d-2174598574ca"
      },
      "source": [
        "df_sub.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.jpg</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.jpg</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.jpg</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.jpg</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id label\n",
              "0  1.jpg   cat\n",
              "1  2.jpg   cat\n",
              "2  3.jpg   cat\n",
              "3  4.jpg   cat\n",
              "4  5.jpg   cat"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJp95LKwBJrT"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train,val= train_test_split(df_train, test_size=0.1)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "sprh3_9RDEcj",
        "outputId": "27ec5eb3-42f3-4d99-8bbd-106f3b74e0fc"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Files</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5786</th>\n",
              "      <td>cat.3956.jpg</td>\n",
              "      <td>cat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20723</th>\n",
              "      <td>dog.6149.jpg</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13415</th>\n",
              "      <td>dog.10820.jpg</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17067</th>\n",
              "      <td>dog.2859.jpg</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17200</th>\n",
              "      <td>dog.2979.jpg</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Files Labels\n",
              "5786    cat.3956.jpg    cat\n",
              "20723   dog.6149.jpg    dog\n",
              "13415  dog.10820.jpg    dog\n",
              "17067   dog.2859.jpg    dog\n",
              "17200   dog.2979.jpg    dog"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szRnunTBgNxy"
      },
      "source": [
        "train.to_csv(FLDR+'Train.csv',index=False)\n",
        "val.to_csv(FLDR+'Validate.csv',index=False)\n",
        "df_sub.to_csv(FLDR+'Test.csv',index=False)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe9h1qgutHFz"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmbGINMztJ2u"
      },
      "source": [
        "train=pd.read_csv(FLDR+'Train.csv')\n",
        "val=pd.read_csv(FLDR+'Validate.csv')\n",
        "df_sub=pd.read_csv(FLDR+'Test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4nQ40GHDY7l"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJa8EMkqDku9"
      },
      "source": [
        "train_set=ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.1,\n",
        "    shear_range=0.2,\n",
        ")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5mO4TiuEoPN"
      },
      "source": [
        "val_set=ImageDataGenerator()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Mw6TxabE6Vr",
        "outputId": "d137ab2b-4961-42e3-dc4e-a48743764a7c"
      },
      "source": [
        "train_gen=train_set.flow_from_dataframe(\n",
        "    train,\n",
        "    directory=FLDR+'extracted/train/',\n",
        "    x_col='Files',\n",
        "    y_col='Labels',\n",
        "    batch_size=16,\n",
        "    class_mode='binary',\n",
        "    target_size=(224, 224),\n",
        ")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 22499 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9mTkqb8Fz4p",
        "outputId": "ebfcbe1c-1a89-48e5-c4b7-39503fd6a491"
      },
      "source": [
        "val_gen=val_set.flow_from_dataframe(\n",
        "    val,\n",
        "    directory=FLDR+'extracted/train/',\n",
        "    x_col='Files',\n",
        "    y_col='Labels',\n",
        "    batch_size=16,\n",
        "    class_mode='binary',\n",
        "    target_size=(224, 224),\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2500 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL8RO-SXGeX6"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, Input\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJr-XtgiIO0X"
      },
      "source": [
        "def model(shape=(224,224,3)):\n",
        "  input_tensor=Input(shape=shape)             \n",
        "\n",
        "  base_model = ResNet50V2(weights=\"imagenet\", include_top=False, input_tensor=input_tensor)   \n",
        "\n",
        "  layer_1=Flatten()(base_model.output)\n",
        "  layer_2=Dense(512, activation='relu')(layer_1)\n",
        "  layer_2_d=Dropout(0.3)(layer_2)\n",
        "  output=Dense(1, activation='sigmoid')(layer_2_d)\n",
        "\n",
        "  model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "  model.compile(optimizer=optimizers.Adam(lr=0.01), loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNn1Lc0eMjPB"
      },
      "source": [
        "Model=model()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgevLgStMmeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "729283b4-1726-4f58-888b-aebed30cb133"
      },
      "source": [
        "Model.summary()\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 56, 56, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 56, 56, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 56, 56, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 56, 56, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 58, 58, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 28, 28, 256)  0           max_pooling2d_6[0][0]            \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 28, 28, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 28, 28, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 28, 28, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 28, 28, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 30, 30, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 14, 14, 512)  0           max_pooling2d_7[0][0]            \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 14, 14, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 14, 14, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 14, 14, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 14, 14, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 16, 16, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 7, 7, 1024)   0           max_pooling2d_8[0][0]            \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 7, 7, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 7, 7, 2048)   8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 7, 7, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 9, 9, 512)    0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 7, 7, 2048)   8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 7, 7, 2048)   0           post_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 100352)       0           post_relu[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 512)          51380736    flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 512)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            513         dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 74,946,049\n",
            "Trainable params: 51,381,249\n",
            "Non-trainable params: 23,564,800\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lspLP99XND-N"
      },
      "source": [
        "checkpoint = ModelCheckpoint(FLDR+\"Model.h5\", monitor='val_accuracy', save_best_only=True, mode='max') #creating checkpoint to save the best validation accuracy\n",
        "callbacks_list = [checkpoint]\n",
        "history = Model.fit_generator(train_gen, validation_data = val_gen, steps_per_epoch=50, callbacks=callbacks_list,verbose=1,epochs = 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aBUtvJVNoil"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, Input\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6kknkx_NKzM"
      },
      "source": [
        "def model(shape=(224,224,3)):\n",
        "  input_tensor=Input(shape=shape)             \n",
        "\n",
        "  base_model = VGG16(weights=\"imagenet\", include_top=False, input_tensor=input_tensor)   \n",
        "\n",
        "  layer_1=Flatten()(base_model.output)\n",
        "  layer_2=Dense(512, activation='relu')(layer_1)\n",
        "  layer_2_d=Dropout(0.3)(layer_2)\n",
        "  output=Dense(1, activation='sigmoid')(layer_2_d)\n",
        "\n",
        "  model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "  model.compile(optimizer=optimizers.Adam(lr=0.01), loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXgHUOFzNaK4",
        "outputId": "f2dd06c5-89ae-4684-8a86-e4b92b4c2afd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Model=model()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os_0_OpZNdoM",
        "outputId": "0e1b6383-ec79-4c36-d1d8-25cc92e0a666",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Model.summary()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               12845568  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 27,560,769\n",
            "Trainable params: 12,846,081\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SFtYgzXNfPk",
        "outputId": "db6174fa-7c15-43cb-8d76-ac32cbf9702f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "checkpoint = ModelCheckpoint(FLDR+\"Model.h5\", monitor='val_accuracy', save_best_only=True, mode='max') #creating checkpoint to save the best validation accuracy\n",
        "callbacks_list = [checkpoint]\n",
        "history = Model.fit_generator(train_gen, validation_data = val_gen, steps_per_epoch=50, callbacks=callbacks_list,verbose=1,epochs = 50)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "50/50 [==============================] - 25s 448ms/step - loss: 261.5785 - accuracy: 0.7503 - val_loss: 27.4158 - val_accuracy: 0.9428\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 21s 432ms/step - loss: 28.3273 - accuracy: 0.9259 - val_loss: 13.0929 - val_accuracy: 0.9308\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 21s 428ms/step - loss: 6.7919 - accuracy: 0.9458 - val_loss: 3.4825 - val_accuracy: 0.9624\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 22s 430ms/step - loss: 3.5229 - accuracy: 0.9370 - val_loss: 1.9076 - val_accuracy: 0.9548\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 21s 430ms/step - loss: 3.0951 - accuracy: 0.9196 - val_loss: 1.3164 - val_accuracy: 0.9596\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 21s 429ms/step - loss: 3.9877 - accuracy: 0.9162 - val_loss: 1.4385 - val_accuracy: 0.9444\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 21s 434ms/step - loss: 2.4474 - accuracy: 0.9060 - val_loss: 0.7746 - val_accuracy: 0.9628\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 22s 440ms/step - loss: 0.4985 - accuracy: 0.9557 - val_loss: 0.7157 - val_accuracy: 0.9564\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 22s 437ms/step - loss: 0.9061 - accuracy: 0.9528 - val_loss: 0.3413 - val_accuracy: 0.9596\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 21s 434ms/step - loss: 0.4911 - accuracy: 0.9278 - val_loss: 1.0122 - val_accuracy: 0.9408\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 21s 430ms/step - loss: 0.6312 - accuracy: 0.9200 - val_loss: 0.3104 - val_accuracy: 0.9524\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 21s 431ms/step - loss: 1.7905 - accuracy: 0.9180 - val_loss: 0.3449 - val_accuracy: 0.9512\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 22s 435ms/step - loss: 0.3255 - accuracy: 0.9274 - val_loss: 0.3689 - val_accuracy: 0.9584\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 21s 429ms/step - loss: 0.4985 - accuracy: 0.9472 - val_loss: 0.3333 - val_accuracy: 0.9584\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 21s 431ms/step - loss: 0.2432 - accuracy: 0.9452 - val_loss: 0.2074 - val_accuracy: 0.9528\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 21s 429ms/step - loss: 0.4596 - accuracy: 0.9263 - val_loss: 0.2494 - val_accuracy: 0.9520\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 21s 426ms/step - loss: 0.3811 - accuracy: 0.9138 - val_loss: 0.1768 - val_accuracy: 0.9588\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 21s 421ms/step - loss: 0.4814 - accuracy: 0.9524 - val_loss: 0.2881 - val_accuracy: 0.9564\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 21s 428ms/step - loss: 0.3883 - accuracy: 0.9477 - val_loss: 1.2021 - val_accuracy: 0.9480\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 21s 425ms/step - loss: 0.4090 - accuracy: 0.9397 - val_loss: 0.3902 - val_accuracy: 0.9528\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 21s 426ms/step - loss: 0.1706 - accuracy: 0.9383 - val_loss: 0.3817 - val_accuracy: 0.9504\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 21s 428ms/step - loss: 1.8582 - accuracy: 0.9282 - val_loss: 0.3014 - val_accuracy: 0.9488\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 21s 425ms/step - loss: 0.7465 - accuracy: 0.9342 - val_loss: 0.4028 - val_accuracy: 0.9320\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 21s 427ms/step - loss: 0.2241 - accuracy: 0.9001 - val_loss: 0.3868 - val_accuracy: 0.9400\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 21s 424ms/step - loss: 0.4844 - accuracy: 0.9276 - val_loss: 0.3605 - val_accuracy: 0.9440\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 21s 425ms/step - loss: 0.4572 - accuracy: 0.9069 - val_loss: 0.1925 - val_accuracy: 0.9604\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 21s 425ms/step - loss: 0.9225 - accuracy: 0.9443 - val_loss: 0.1867 - val_accuracy: 0.9628\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 21s 429ms/step - loss: 0.1720 - accuracy: 0.9287 - val_loss: 0.2352 - val_accuracy: 0.9596\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 21s 425ms/step - loss: 1.4149 - accuracy: 0.9325 - val_loss: 0.4664 - val_accuracy: 0.9608\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 21s 429ms/step - loss: 0.4097 - accuracy: 0.9081 - val_loss: 0.2631 - val_accuracy: 0.9468\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 21s 428ms/step - loss: 0.3178 - accuracy: 0.9487 - val_loss: 0.2921 - val_accuracy: 0.9440\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 21s 427ms/step - loss: 0.2115 - accuracy: 0.9251 - val_loss: 0.5736 - val_accuracy: 0.9472\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 21s 429ms/step - loss: 0.8695 - accuracy: 0.9230 - val_loss: 0.4410 - val_accuracy: 0.9196\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 21s 428ms/step - loss: 2.4601 - accuracy: 0.8700 - val_loss: 0.2472 - val_accuracy: 0.9260\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 21s 425ms/step - loss: 1.1766 - accuracy: 0.8547 - val_loss: 0.3767 - val_accuracy: 0.9512\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 21s 426ms/step - loss: 0.6714 - accuracy: 0.9142 - val_loss: 0.2661 - val_accuracy: 0.9384\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 21s 424ms/step - loss: 0.3905 - accuracy: 0.9197 - val_loss: 0.5977 - val_accuracy: 0.9528\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 21s 426ms/step - loss: 0.3953 - accuracy: 0.8907 - val_loss: 0.4739 - val_accuracy: 0.9384\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 22s 435ms/step - loss: 0.3703 - accuracy: 0.8818 - val_loss: 0.3748 - val_accuracy: 0.9432\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 21s 420ms/step - loss: 1.2605 - accuracy: 0.8913 - val_loss: 0.5665 - val_accuracy: 0.9392\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 21s 420ms/step - loss: 0.8402 - accuracy: 0.8965 - val_loss: 0.2309 - val_accuracy: 0.9068\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 21s 417ms/step - loss: 0.3804 - accuracy: 0.8592 - val_loss: 0.2792 - val_accuracy: 0.8504\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 21s 419ms/step - loss: 2.6584 - accuracy: 0.8046 - val_loss: 0.4886 - val_accuracy: 0.8960\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 21s 424ms/step - loss: 1.6932 - accuracy: 0.8434 - val_loss: 0.3576 - val_accuracy: 0.9352\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 21s 418ms/step - loss: 0.7305 - accuracy: 0.8629 - val_loss: 0.4020 - val_accuracy: 0.9188\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 21s 418ms/step - loss: 0.4203 - accuracy: 0.8818 - val_loss: 0.2798 - val_accuracy: 0.9040\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 21s 420ms/step - loss: 1.0564 - accuracy: 0.8217 - val_loss: 0.2171 - val_accuracy: 0.9040\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 21s 417ms/step - loss: 0.5346 - accuracy: 0.8349 - val_loss: 0.2506 - val_accuracy: 0.8648\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 21s 417ms/step - loss: 0.3469 - accuracy: 0.7920 - val_loss: 0.2289 - val_accuracy: 0.8864\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 21s 419ms/step - loss: 0.5227 - accuracy: 0.8099 - val_loss: 0.3024 - val_accuracy: 0.8144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWWEYyyaR3D5"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q13x3MbaR1ml",
        "outputId": "719abfd6-4c8f-4bb7-9f35-bf7b6fc9c40f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "#plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n",
        "                    wspace=0.35)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tBBSaTMR_ji"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, Input\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1sMOsgxS3Eo"
      },
      "source": [
        "def model(shape=(224,224,3)):\n",
        "  input_tensor=Input(shape=shape)             \n",
        "\n",
        "  base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_tensor=input_tensor)   \n",
        "\n",
        "  layer_1=Flatten()(base_model.output)\n",
        "  layer_2=Dense(512, activation='relu')(layer_1)\n",
        "  layer_2_d=Dropout(0.3)(layer_2)\n",
        "  output=Dense(1, activation='sigmoid')(layer_2_d)\n",
        "\n",
        "  model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "  model.compile(optimizer=optimizers.Adam(lr=0.01), loss='binary_crossentropy',metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njHNqFUlS-kZ"
      },
      "source": [
        "Model=model()"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC5FZk1-TC2s",
        "outputId": "885aeec9-27e1-4c91-f236-d7c26047aa8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Model.summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 111, 111, 32) 864         input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 111, 111, 32) 96          conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 111, 111, 32) 0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 109, 109, 32) 9216        activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 109, 109, 32) 96          conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 109, 109, 32) 0           batch_normalization_189[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 109, 109, 64) 18432       activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 109, 109, 64) 192         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 109, 109, 64) 0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 54, 54, 64)   0           activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 54, 54, 80)   5120        max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 54, 54, 80)   240         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 54, 54, 80)   0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 52, 52, 192)  138240      activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 52, 52, 192)  576         conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 52, 52, 192)  0           batch_normalization_192[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling2D) (None, 25, 25, 192)  0           activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 25, 25, 64)   192         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 25, 25, 64)   0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 25, 25, 48)   9216        max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 25, 25, 96)   55296       activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 25, 25, 48)   144         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 25, 25, 96)   288         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 25, 25, 48)   0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 25, 25, 96)   0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_18 (AveragePo (None, 25, 25, 192)  0           max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 25, 25, 64)   12288       max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 25, 25, 64)   76800       activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 25, 25, 96)   82944       activation_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 25, 25, 32)   6144        average_pooling2d_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 25, 25, 64)   192         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 25, 25, 64)   192         conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 25, 25, 96)   288         conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 25, 25, 32)   96          conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 25, 25, 64)   0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 25, 25, 64)   0           batch_normalization_195[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_198 (Activation)     (None, 25, 25, 96)   0           batch_normalization_198[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_199 (Activation)     (None, 25, 25, 32)   0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_193[0][0]             \n",
            "                                                                 activation_195[0][0]             \n",
            "                                                                 activation_198[0][0]             \n",
            "                                                                 activation_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 25, 25, 64)   192         conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_203 (Activation)     (None, 25, 25, 64)   0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 25, 25, 96)   55296       activation_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 25, 25, 48)   144         conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 25, 25, 96)   288         conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_201 (Activation)     (None, 25, 25, 48)   0           batch_normalization_201[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, 25, 25, 96)   0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_19 (AveragePo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 25, 25, 64)   76800       activation_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 25, 25, 96)   82944       activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 25, 25, 64)   16384       average_pooling2d_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 25, 25, 64)   192         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 25, 25, 64)   192         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 25, 25, 96)   288         conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 25, 25, 64)   192         conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_200 (Activation)     (None, 25, 25, 64)   0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_202 (Activation)     (None, 25, 25, 64)   0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, 25, 25, 96)   0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, 25, 25, 64)   0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_200[0][0]             \n",
            "                                                                 activation_202[0][0]             \n",
            "                                                                 activation_205[0][0]             \n",
            "                                                                 activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 25, 25, 64)   192         conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 25, 25, 64)   0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 25, 25, 96)   55296       activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 25, 25, 48)   144         conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 25, 25, 96)   288         conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 25, 25, 48)   0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 25, 25, 96)   0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_20 (AveragePo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 25, 25, 64)   76800       activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 25, 25, 96)   82944       activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 25, 25, 64)   18432       average_pooling2d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 25, 25, 64)   192         conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 25, 25, 64)   192         conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 25, 25, 96)   288         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 25, 25, 64)   192         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, 25, 25, 64)   0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 25, 25, 64)   0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 25, 25, 96)   0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 25, 25, 64)   0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_207[0][0]             \n",
            "                                                                 activation_209[0][0]             \n",
            "                                                                 activation_212[0][0]             \n",
            "                                                                 activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 25, 25, 64)   192         conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 25, 25, 64)   0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 25, 25, 96)   55296       activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 25, 25, 96)   288         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 25, 25, 96)   0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 12, 12, 96)   82944       activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 12, 12, 384)  1152        conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 12, 12, 96)   288         conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 12, 12, 384)  0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 12, 12, 96)   0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling2D) (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_214[0][0]             \n",
            "                                                                 activation_217[0][0]             \n",
            "                                                                 max_pooling2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 12, 12, 128)  384         conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 12, 12, 128)  0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 12, 12, 128)  114688      activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 12, 12, 128)  384         conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 12, 12, 128)  0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 12, 12, 128)  114688      activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 12, 12, 128)  384         conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 12, 12, 128)  384         conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 12, 12, 128)  0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 12, 12, 128)  0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 12, 12, 128)  114688      activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 12, 12, 128)  114688      activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 12, 12, 128)  384         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 12, 12, 128)  384         conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 12, 12, 128)  0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 12, 12, 128)  0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_21 (AveragePo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 12, 12, 192)  172032      activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 12, 12, 192)  172032      activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 12, 12, 192)  576         conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 12, 12, 192)  576         conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 12, 12, 192)  576         conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 12, 12, 192)  576         conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 12, 12, 192)  0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 12, 12, 192)  0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 12, 12, 192)  0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 12, 12, 192)  0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_218[0][0]             \n",
            "                                                                 activation_221[0][0]             \n",
            "                                                                 activation_226[0][0]             \n",
            "                                                                 activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 12, 12, 160)  480         conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 12, 12, 160)  0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 12, 12, 160)  179200      activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 12, 12, 160)  480         conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 12, 12, 160)  0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 12, 12, 160)  179200      activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 12, 12, 160)  480         conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 12, 12, 160)  480         conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 12, 12, 160)  0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 12, 12, 160)  0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 12, 12, 160)  179200      activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 12, 12, 160)  179200      activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 12, 12, 160)  480         conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 12, 12, 160)  480         conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 12, 12, 160)  0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 12, 12, 160)  0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_22 (AveragePo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 12, 12, 192)  215040      activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 12, 12, 192)  215040      activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 12, 12, 192)  576         conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 12, 12, 192)  576         conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 12, 12, 192)  576         conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 12, 12, 192)  576         conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 12, 12, 192)  0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 12, 12, 192)  0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 12, 12, 192)  0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 12, 12, 192)  0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_228[0][0]             \n",
            "                                                                 activation_231[0][0]             \n",
            "                                                                 activation_236[0][0]             \n",
            "                                                                 activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 12, 12, 160)  480         conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 12, 12, 160)  0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 12, 12, 160)  179200      activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 12, 12, 160)  480         conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 12, 12, 160)  0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 12, 12, 160)  179200      activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 12, 12, 160)  480         conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 12, 12, 160)  480         conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 12, 12, 160)  0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 12, 12, 160)  0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 12, 12, 160)  179200      activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 12, 12, 160)  179200      activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 12, 12, 160)  480         conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 12, 12, 160)  480         conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 12, 12, 160)  0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 12, 12, 160)  0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_23 (AveragePo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 12, 12, 192)  215040      activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 12, 12, 192)  215040      activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 12, 12, 192)  576         conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 12, 12, 192)  576         conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 12, 12, 192)  576         conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 12, 12, 192)  576         conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 12, 12, 192)  0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 12, 12, 192)  0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 12, 12, 192)  0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 12, 12, 192)  0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_238[0][0]             \n",
            "                                                                 activation_241[0][0]             \n",
            "                                                                 activation_246[0][0]             \n",
            "                                                                 activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 12, 12, 192)  576         conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 12, 12, 192)  0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 12, 12, 192)  258048      activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 12, 12, 192)  576         conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 12, 12, 192)  0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 12, 12, 192)  258048      activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 12, 12, 192)  576         conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 12, 12, 192)  576         conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 12, 12, 192)  0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 12, 12, 192)  0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 12, 12, 192)  258048      activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 12, 12, 192)  258048      activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 12, 12, 192)  576         conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 12, 12, 192)  576         conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 12, 12, 192)  0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 12, 12, 192)  0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_24 (AveragePo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 12, 12, 192)  258048      activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 12, 12, 192)  258048      activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 12, 12, 192)  147456      average_pooling2d_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 12, 12, 192)  576         conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 12, 12, 192)  576         conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 12, 12, 192)  576         conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 12, 12, 192)  576         conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 12, 12, 192)  0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 12, 12, 192)  0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 12, 12, 192)  0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 12, 12, 192)  0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_248[0][0]             \n",
            "                                                                 activation_251[0][0]             \n",
            "                                                                 activation_256[0][0]             \n",
            "                                                                 activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 12, 12, 192)  576         conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 12, 12, 192)  0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 12, 12, 192)  258048      activation_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 12, 12, 192)  576         conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 12, 12, 192)  0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 12, 12, 192)  258048      activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, 12, 12, 192)  576         conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 12, 12, 192)  576         conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 12, 12, 192)  0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 12, 12, 192)  0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 5, 5, 320)    552960      activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 5, 5, 192)    331776      activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, 5, 5, 320)    960         conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 5, 5, 192)    576         conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 5, 5, 320)    0           batch_normalization_259[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 5, 5, 192)    0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling2D) (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_259[0][0]             \n",
            "                                                                 activation_263[0][0]             \n",
            "                                                                 max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 5, 5, 448)    1344        conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 5, 5, 448)    0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 5, 5, 384)    1548288     activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 5, 5, 384)    1152        conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 5, 5, 384)    1152        conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 5, 5, 384)    0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 5, 5, 384)    0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 5, 5, 384)    442368      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 5, 5, 384)    442368      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 5, 5, 384)    442368      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 5, 5, 384)    442368      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_25 (AveragePo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 5, 5, 384)    1152        conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 5, 5, 384)    1152        conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, 5, 5, 384)    1152        conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, 5, 5, 384)    1152        conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 5, 5, 192)    245760      average_pooling2d_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 5, 5, 320)    960         conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 5, 5, 384)    0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 5, 5, 384)    0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 5, 5, 384)    0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 5, 5, 384)    0           batch_normalization_271[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, 5, 5, 192)    576         conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 5, 5, 320)    0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_266[0][0]             \n",
            "                                                                 activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 5, 5, 768)    0           activation_270[0][0]             \n",
            "                                                                 activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 5, 5, 192)    0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_264[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_4[0][0]              \n",
            "                                                                 activation_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 5, 5, 448)    1344        conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 5, 5, 448)    0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 5, 5, 384)    1548288     activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 5, 5, 384)    1152        conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 5, 5, 384)    1152        conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 5, 5, 384)    0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 5, 5, 384)    0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 5, 5, 384)    442368      activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 5, 5, 384)    442368      activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 5, 5, 384)    442368      activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 5, 5, 384)    442368      activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_26 (AveragePo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 5, 5, 384)    1152        conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 5, 5, 384)    1152        conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 5, 5, 384)    1152        conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 5, 5, 384)    1152        conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 5, 5, 192)    393216      average_pooling2d_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 5, 5, 320)    960         conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 5, 5, 384)    0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 5, 5, 384)    0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 5, 5, 384)    0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 5, 5, 384)    0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 5, 5, 192)    576         conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 5, 5, 320)    0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_275[0][0]             \n",
            "                                                                 activation_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 5, 5, 768)    0           activation_279[0][0]             \n",
            "                                                                 activation_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 5, 5, 192)    0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_273[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_5[0][0]              \n",
            "                                                                 activation_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 51200)        0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 512)          26214912    flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 512)          0           dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 1)            513         dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 48,018,209\n",
            "Trainable params: 47,983,777\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUZVXGsuTHLa",
        "outputId": "094421d4-6353-47ef-b430-aac282cc47ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "checkpoint = ModelCheckpoint(FLDR+\"Model.h5\", monitor='val_accuracy', save_best_only=True, mode='max') #creating checkpoint to save the best validation accuracy\n",
        "callbacks_list = [checkpoint]\n",
        "history = Model.fit_generator(train_gen, validation_data = val_gen, steps_per_epoch=50, callbacks=callbacks_list,verbose=1,epochs = 50)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "50/50 [==============================] - 33s 523ms/step - loss: 25.8590 - accuracy: 0.5412 - val_loss: 411583152128.0000 - val_accuracy: 0.5032\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 25s 496ms/step - loss: 3.5603 - accuracy: 0.4677 - val_loss: 441977824.0000 - val_accuracy: 0.4968\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 23s 463ms/step - loss: 1.5863 - accuracy: 0.4933 - val_loss: 4691.9746 - val_accuracy: 0.4968\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 23s 463ms/step - loss: 0.7491 - accuracy: 0.5051 - val_loss: 14.6895 - val_accuracy: 0.4968\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 23s 464ms/step - loss: 0.6876 - accuracy: 0.5094 - val_loss: 0.7143 - val_accuracy: 0.5072\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 25s 497ms/step - loss: 0.6915 - accuracy: 0.5347 - val_loss: 0.6944 - val_accuracy: 0.5036\n",
            "Epoch 7/50\n",
            "50/50 [==============================] - 23s 462ms/step - loss: 0.7069 - accuracy: 0.4467 - val_loss: 0.7455 - val_accuracy: 0.5088\n",
            "Epoch 8/50\n",
            "50/50 [==============================] - 24s 493ms/step - loss: 0.7175 - accuracy: 0.4774 - val_loss: 0.6934 - val_accuracy: 0.4912\n",
            "Epoch 9/50\n",
            "50/50 [==============================] - 23s 462ms/step - loss: 0.6999 - accuracy: 0.5073 - val_loss: 0.7031 - val_accuracy: 0.5024\n",
            "Epoch 10/50\n",
            "50/50 [==============================] - 23s 459ms/step - loss: 0.7077 - accuracy: 0.5284 - val_loss: 0.9152 - val_accuracy: 0.5092\n",
            "Epoch 11/50\n",
            "50/50 [==============================] - 24s 492ms/step - loss: 0.8070 - accuracy: 0.5131 - val_loss: 1.6026 - val_accuracy: 0.4960\n",
            "Epoch 12/50\n",
            "50/50 [==============================] - 23s 461ms/step - loss: 0.7188 - accuracy: 0.5123 - val_loss: 0.6994 - val_accuracy: 0.5028\n",
            "Epoch 13/50\n",
            "50/50 [==============================] - 23s 460ms/step - loss: 0.6931 - accuracy: 0.5085 - val_loss: 0.6942 - val_accuracy: 0.4964\n",
            "Epoch 14/50\n",
            "50/50 [==============================] - 23s 460ms/step - loss: 0.6945 - accuracy: 0.4923 - val_loss: 0.6971 - val_accuracy: 0.4968\n",
            "Epoch 15/50\n",
            "50/50 [==============================] - 23s 462ms/step - loss: 0.6943 - accuracy: 0.5290 - val_loss: 0.6934 - val_accuracy: 0.4964\n",
            "Epoch 16/50\n",
            "50/50 [==============================] - 23s 459ms/step - loss: 0.6936 - accuracy: 0.4952 - val_loss: 0.7124 - val_accuracy: 0.5016\n",
            "Epoch 17/50\n",
            "50/50 [==============================] - 23s 460ms/step - loss: 0.7359 - accuracy: 0.5038 - val_loss: 0.7593 - val_accuracy: 0.5048\n",
            "Epoch 18/50\n",
            "50/50 [==============================] - 23s 460ms/step - loss: 0.6960 - accuracy: 0.5033 - val_loss: 0.7119 - val_accuracy: 0.4996\n",
            "Epoch 19/50\n",
            "50/50 [==============================] - 23s 460ms/step - loss: 0.6968 - accuracy: 0.5558 - val_loss: 0.6936 - val_accuracy: 0.5004\n",
            "Epoch 20/50\n",
            "50/50 [==============================] - 23s 461ms/step - loss: 0.6939 - accuracy: 0.5254 - val_loss: 0.7412 - val_accuracy: 0.5064\n",
            "Epoch 21/50\n",
            "50/50 [==============================] - 23s 462ms/step - loss: 0.6952 - accuracy: 0.4848 - val_loss: 0.6929 - val_accuracy: 0.5016\n",
            "Epoch 22/50\n",
            "50/50 [==============================] - 23s 460ms/step - loss: 0.6992 - accuracy: 0.5072 - val_loss: 0.6951 - val_accuracy: 0.4972\n",
            "Epoch 23/50\n",
            "50/50 [==============================] - 23s 458ms/step - loss: 0.6921 - accuracy: 0.5218 - val_loss: 0.7060 - val_accuracy: 0.5124\n",
            "Epoch 24/50\n",
            "50/50 [==============================] - 24s 493ms/step - loss: 0.6946 - accuracy: 0.4884 - val_loss: 0.6931 - val_accuracy: 0.5024\n",
            "Epoch 25/50\n",
            "50/50 [==============================] - 23s 460ms/step - loss: 0.6936 - accuracy: 0.5199 - val_loss: 0.6935 - val_accuracy: 0.4968\n",
            "Epoch 26/50\n",
            "50/50 [==============================] - 23s 459ms/step - loss: 0.6928 - accuracy: 0.5135 - val_loss: 0.6938 - val_accuracy: 0.4984\n",
            "Epoch 27/50\n",
            "50/50 [==============================] - 23s 460ms/step - loss: 0.6940 - accuracy: 0.5087 - val_loss: 0.6932 - val_accuracy: 0.5024\n",
            "Epoch 28/50\n",
            "50/50 [==============================] - 23s 457ms/step - loss: 0.6927 - accuracy: 0.5139 - val_loss: 0.6934 - val_accuracy: 0.4968\n",
            "Epoch 29/50\n",
            "50/50 [==============================] - 23s 460ms/step - loss: 0.6934 - accuracy: 0.4936 - val_loss: 0.6933 - val_accuracy: 0.4968\n",
            "Epoch 30/50\n",
            "50/50 [==============================] - 23s 459ms/step - loss: 0.6936 - accuracy: 0.4979 - val_loss: 0.6932 - val_accuracy: 0.4968\n",
            "Epoch 31/50\n",
            "50/50 [==============================] - 23s 457ms/step - loss: 0.6935 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5032\n",
            "Epoch 32/50\n",
            "50/50 [==============================] - 23s 463ms/step - loss: 0.6935 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5032\n",
            "Epoch 33/50\n",
            "50/50 [==============================] - 23s 457ms/step - loss: 0.6933 - accuracy: 0.5049 - val_loss: 0.6933 - val_accuracy: 0.4968\n",
            "Epoch 34/50\n",
            "50/50 [==============================] - 23s 459ms/step - loss: 0.6939 - accuracy: 0.4868 - val_loss: 0.6932 - val_accuracy: 0.5032\n",
            "Epoch 35/50\n",
            "50/50 [==============================] - 23s 465ms/step - loss: 0.6942 - accuracy: 0.4857 - val_loss: 0.6933 - val_accuracy: 0.5032\n",
            "Epoch 36/50\n",
            "50/50 [==============================] - 23s 458ms/step - loss: 0.6927 - accuracy: 0.5220 - val_loss: 0.6934 - val_accuracy: 0.5032\n",
            "Epoch 37/50\n",
            "50/50 [==============================] - 23s 461ms/step - loss: 0.6954 - accuracy: 0.4576 - val_loss: 0.6931 - val_accuracy: 0.5068\n",
            "Epoch 38/50\n",
            "50/50 [==============================] - 23s 465ms/step - loss: 0.6932 - accuracy: 0.5075 - val_loss: 0.6935 - val_accuracy: 0.4968\n",
            "Epoch 39/50\n",
            "50/50 [==============================] - 23s 458ms/step - loss: 0.6924 - accuracy: 0.5181 - val_loss: 0.6930 - val_accuracy: 0.5092\n",
            "Epoch 40/50\n",
            "50/50 [==============================] - 23s 460ms/step - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6944 - val_accuracy: 0.5032\n",
            "Epoch 41/50\n",
            "50/50 [==============================] - 23s 463ms/step - loss: 0.6976 - accuracy: 0.4795 - val_loss: 0.6942 - val_accuracy: 0.4964\n",
            "Epoch 42/50\n",
            "50/50 [==============================] - 23s 463ms/step - loss: 0.6976 - accuracy: 0.4663 - val_loss: 0.6932 - val_accuracy: 0.5032\n",
            "Epoch 43/50\n",
            "50/50 [==============================] - 23s 458ms/step - loss: 0.6935 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5032\n",
            "Epoch 44/50\n",
            "50/50 [==============================] - 23s 463ms/step - loss: 0.6932 - accuracy: 0.5148 - val_loss: 0.6931 - val_accuracy: 0.5032\n",
            "Epoch 45/50\n",
            "50/50 [==============================] - 23s 460ms/step - loss: 0.6947 - accuracy: 0.5408 - val_loss: 0.6938 - val_accuracy: 0.4968\n",
            "Epoch 46/50\n",
            "50/50 [==============================] - 23s 460ms/step - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6928 - val_accuracy: 0.5032\n",
            "Epoch 47/50\n",
            "50/50 [==============================] - 23s 454ms/step - loss: 0.6951 - accuracy: 0.4660 - val_loss: 0.6932 - val_accuracy: 0.5008\n",
            "Epoch 48/50\n",
            "50/50 [==============================] - 23s 459ms/step - loss: 0.6944 - accuracy: 0.4949 - val_loss: 0.6933 - val_accuracy: 0.5032\n",
            "Epoch 49/50\n",
            "50/50 [==============================] - 23s 457ms/step - loss: 0.6943 - accuracy: 0.4860 - val_loss: 0.6935 - val_accuracy: 0.4968\n",
            "Epoch 50/50\n",
            "50/50 [==============================] - 23s 457ms/step - loss: 0.6943 - accuracy: 0.4872 - val_loss: 0.6937 - val_accuracy: 0.4968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1_mSWZQTMZk",
        "outputId": "a106bf26-2ac5-4503-f763-126b6020f314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "#plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.subplots_adjust(top=1.00, bottom=0.0, left=0.0, right=0.95, hspace=0.25,\n",
        "                    wspace=0.35)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCwxq4Tsdx2h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}